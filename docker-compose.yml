services:
  # Vector Database (Qdrant)
  vectordb:
    image: qdrant/qdrant:v1.12.1
    container_name: ragbrain-vectordb
    ports:
      - "6333:6333"
      - "6334:6334"  # gRPC port
    volumes:
      - ${DATA_DIR:-./data}/qdrant:/qdrant/storage
    environment:
      # Memory optimization settings
      - QDRANT__STORAGE__PERFORMANCE__MAX_OPTIMIZATION_THREADS=2
      - QDRANT__STORAGE__ON_DISK_PAYLOAD=true
      - QDRANT__STORAGE__OPTIMIZERS__MEMMAP_THRESHOLD_KB=10000
      - QDRANT__STORAGE__OPTIMIZERS__INDEXING_THRESHOLD_KB=10000
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 512M
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "timeout 1 bash -c '</dev/tcp/localhost/6333' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Redis (for namespace provider - optional, enable via NAMESPACE_PROVIDER=redis)
  redis:
    image: redis:7-alpine
    container_name: ragbrain-redis
    command: redis-server --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - ${DATA_DIR:-./data}/redis:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Application (FastAPI backend + Vue frontend)
  app:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: ragbrain-app
    ports:
      - "8000:8000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      # API Keys
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - COHERE_API_KEY=${COHERE_API_KEY:-}
      - MIXEDBREAD_API_KEY=${MIXEDBREAD_API_KEY:-}
      # Providers (defaults)
      - LLM_PROVIDER=${LLM_PROVIDER:-fallback}
      - EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER:-openai}
      - VECTORDB_PROVIDER=${VECTORDB_PROVIDER:-qdrant}
      # Namespace provider (sqlite or redis)
      - NAMESPACE_PROVIDER=${NAMESPACE_PROVIDER:-sqlite}
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=6379
      - REDIS_DB=${REDIS_DB:-0}
      # Ollama (running on host)
      - OLLAMA_URL=${OLLAMA_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
      - OLLAMA_EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL:-mxbai-embed-large}
      # LLM Fallback provider configuration
      - FALLBACK_PRIMARY=${FALLBACK_PRIMARY:-ollama}
      - FALLBACK_SECONDARY=${FALLBACK_SECONDARY:-anthropic}
      # Embedding Fallback configuration (ollama -> mixedbread for same 1024 dimensions)
      - EMBEDDING_FALLBACK_PRIMARY=${EMBEDDING_FALLBACK_PRIMARY:-ollama}
      - EMBEDDING_FALLBACK_SECONDARY=${EMBEDDING_FALLBACK_SECONDARY:-mixedbread}
      - MIXEDBREAD_MODEL=${MIXEDBREAD_MODEL:-mxbai-embed-large-v1}
      # Embedding dimension (1024 for Ollama mxbai-embed-large, 1536 for OpenAI)
      - EMBEDDING_DIMENSION=${EMBEDDING_DIMENSION:-1024}
      # Vector DB
      - QDRANT_URL=${QDRANT_URL:-http://vectordb:6333}
      - QDRANT_COLLECTION=${QDRANT_COLLECTION:-ragbrain}
      # App settings
      - CHUNK_SIZE=${CHUNK_SIZE:-2000}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP:-200}
      - DEFAULT_CHUNKING_STRATEGY=${DEFAULT_CHUNKING_STRATEGY:-recursive}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      - ${DATA_DIR:-./data}/uploads:/app/uploads
      - ${DATA_DIR:-./data}:/app/data  # Namespace DB and other app data
    depends_on:
      vectordb:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  qdrant_data:
